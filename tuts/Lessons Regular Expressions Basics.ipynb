{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with text - Regular Expressions\n",
    "When working with text data regular expressions are one of the most indispensable and powerful tools at hand of any programmer. Often refered as 'regexp' they can be applied to search through the texts for certain words and characters, to substitute one word or a part of it for another and, most prominently, to exctract relevant data using patterns. These patterns is what makes them so interesting and useful.\n",
    "\n",
    "For instance, suppose you are looking for words consisting of exact 7 letters, or, say you are interested in names, thus the words that start with the Capital letter. Or just want to extract decimal numbers, maybe you are interested to find any prices scattered across the text (thus, a number followed by a currency sign), how about gathering contact information such as phones, emails appeared in the documents? Those have exact pattern such as (whitehouse phone number) bestemailaddress@google.com. Or You might want to gather all links, which is http:// followed by domain name/address, or, say, you are interested to get whole sentences that contain any of the above. This is where regexps shine.\n",
    "\n",
    "In this lesson we will cover basic techniques that allow to accomplish anything mentioned above and more. Upon finishing it you'll feel confident to work with text, preprocess it and apply regular expressions - all using python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 1 - working with files\n",
    "---\n",
    "An essential step before working with text is to read the files and get acquinted with the contents.\n",
    "This mission explains how to read a single file, a number of files, and as a practical excerise we'll find the number of words each txt file consists of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files\n",
    "To work with text files we first need to read it into the memory.\n",
    "\n",
    "Here is a small file, that contains a piece of poem from Alice in Wonderland by Lewis Caroll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beautiful_soup.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Beautiful Soup, so rich and green,\n",
    "Waiting in a hot tureen!\n",
    "Who for such dainties would not stoop?\n",
    "Soup of the evening, beautiful Soup!\n",
    "Soup of the evening, beautiful Soup!\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "To open a file we can use open() function which creates a fileobject:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('beautiful_soup.txt', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument is a filename, the second is the mode. Mode `'r'` means the object is created for read-only purpose.\n",
    "\n",
    "Now the object can be read, and assigned to a varible using `f.read()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beautiful Soup, so rich and green,\\nWaiting in a hot tureen!\\nWho for such dainties would not stoop?\\nSoup of the evening, beautiful Soup!\\nSoup of the evening, beautiful Soup!\\n...'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_str = f.read()\n",
    "file_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python stores whole text in a variable as a single string.\n",
    "\n",
    "Notice `\\n` character at places where originally there were new lines. `\\n` is a special whitespace character that denotes a new line in any textual data. When you open files with text editors such as notepad, `\\n` are always there but not displayed for convenience.\n",
    "\n",
    "Another example of a whitespace character is `\\t` which denotes a tab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Best pactice](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) when working with files is to use `with` statement as following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Beautiful Soup, so rich and green,\\nWaiting in a hot tureen!\\nWho for such dainties would not stoop?\\nSoup of the evening, beautiful Soup!\\nSoup of the evening, beautiful Soup!\\n...'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('beautiful_soup.txt', 'r') as file:\n",
    "    file_str = file.read()\n",
    "    file_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way python automatically closes the file after each operation, which is memory efficient and especially matters when the files are very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to read several files?\n",
    "\n",
    "To read several documents we can type each filename manually, assign to a new variable and read, which is ok, but not practical if we have many files or difficult names. How about to read all txt files at once?\n",
    "\n",
    "To do that we would first build a list of filenames using `listdir()` function of the `os` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fire_and_ice.txt', 'nothing_gold_can_stay.txt', 'risk.txt', 'trees.txt']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = 'short_poems/'\n",
    "filenames = os.listdir(path)\n",
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can loop through the filenames, choosing only those with `.txt` at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Some say the world will end in fire,\\nSome say in ice.\\nFrom what IвЂ™ve tasted of desire\\nI hold with those who favor fire.\\nBut if it had to perish twice,\\nI think I know enough of hate\\nTo say that for destruction ice\\nIs also great\\nAnd would suffice.\\n\\nAuthor: Robert Frost'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'NatureвЂ™s first green is gold, \\nHer hardest hue to hold. \\nHer early leafвЂ™s a flower; \\nBut only so an hour. \\nThen leaf subsides to leaf. \\nSo Eden sank to grief, \\nSo dawn goes down to day. \\nNothing gold can stay.\\nAuthor: Robert Frost'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'And then the day came,\\nwhen the risk\\nto remain tight\\nin a bud\\nwas more painful\\nthan the risk\\nit took\\nto Blossom.\\nAuthor: AnaГЇs Nin'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "'I think that I shall never see\\nA poem lovely as a tree.\\n\\nA tree whose hungry mouth is prest\\nAgainst the earthвЂ™s sweet flowing breast;\\n\\nA tree that looks at God all day,\\nAnd lifts her leafy arms to pray;\\n\\nA tree that may in Summer wear\\nA nest of robins in her hair;\\n\\nUpon whose bosom snow has lain;\\nWho intimately lives with rain.\\n\\nPoems are made by fools like me,\\nBut only God can make a tree.\\n\\nAuthor: Joyce Kilmer'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for filename in filenames:\n",
    "    if filename.endswith(\".txt\"): \n",
    "        with open(path+filename, 'r') as file:\n",
    "            file_str = file.read()\n",
    "            file_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worth to note how we pass `path+filename` argument to an open() function. `path+filename` comprise a single `path/filename.txt` string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Reading text files is a breeze now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count words\n",
    "To count words in a document, we would need to obtain a list of words. `str.split()` function splits a string by any whitespace character and returns a list words or tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown', 'fox', 'jumps', 'over', 'a', 'lazy', 'dog.']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Brown fox jumps over a lazy dog.'\n",
    "word_list = sentence.split()\n",
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We can find out word number by the lenght of the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words:  7\n"
     ]
    }
   ],
   "source": [
    "print('Words: ',len(word_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are interested to find how many lines are there in the document. We would split the document by a newline character `\\n`, passing it as a parameter to the `str.split()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines:  6\n"
     ]
    }
   ],
   "source": [
    "with open('beautiful_soup.txt', 'r') as file:\n",
    "    file_str = file.read()\n",
    "    lines = file_str.split('\\n')\n",
    "    print('Lines: ',len(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "Find out how large are the documents in number of words.\n",
    "\n",
    "1. Read in all .txt documents.\n",
    "    - Build a list of filenames from `short_poems` folder.\n",
    "    - Loop through only txt filenames.\n",
    "2. Calculate word number for each document.\n",
    "    - split current document as words, and assign list to a variable.\n",
    "    - print name of the document and the number of words it contains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 2 - regular expressions p.1\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 3 - regular expressions p.2\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mission 4 - Project - CIA files\n",
    "A student is presented with a challenge to extract sentences that contain dates from a large number of documents on a disk. Say, 50 files. The files are secret projects spanning the period since 1900 and even up to a future. The aim is to present filenames sorted by the extracted dates with the first line (a header) and sentences that contained this date as a recap.\n",
    "\n",
    "The kink would be that dates appear in text in various forms such as: 1941 Sept 1/1941 September 1/1 September 1941/1941 Sept/1941-09-01/1941 etc. - i.e. different positions of year, month, day and different representations of those. So a major part of the challenge would be to normalize the dates to a single form, and then perform sorting based on the findings.\n",
    "\n",
    "On completion users would have a powerful tool that goes through all text files on a designated path find any dates, and have files and their recap presented sorted by date."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
